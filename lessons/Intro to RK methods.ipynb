{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f635e0-4793-4f7b-8a22-33f3f0b417da",
   "metadata": {},
   "source": [
    "# Introduction to Runge-Kutta methods for approximating solutions to DE's\n",
    "\n",
    "This tutorial gives a quick overview of **Runge-Kutta** (pronounced `RUNG-uh CUT-uh` and often abbreviated RK) methods for approximating solutions to first-order differential equations. RK methods are an upgrade over Euler's method (actually Euler's method is one particular instance of a RK method) and typically provide greater accuracy in the approximations it makes for an equivalent computational cost. The tradeoff is that the individual calculations requires more intricate formulas. \n",
    "\n",
    "## Review of Euler's Method\n",
    "\n",
    "**Euler's Method** for approximating a solution to a DE works like this. Suppose you have a DE $\\frac{dy}{dt} = f(t,y)$ with an initial condition $y(t_0) = y_0$. Then to generate an approximate solution: \n",
    "\n",
    "1. Choose a step size, $h$. (Generally speaking, smaller step sizes give better accuracy but require more steps.) \n",
    "2. Start with the initial values $y_0$ and $t_0$. \n",
    "3. Set $t_1 = t_0 + h$. \n",
    "4. Compute $y_1 = y_0 + f(t_0, y_0) \\cdot h$. That is, the new approximate $y$-value is the previous one, plus the step size times the derivative at the previous $t$ and $y$ values.\n",
    "5. For each subsequent step: Let $t_i = t_{i-1} + h$ (that is, add the step size to the previous $t$ value) and compute $y_i = y_{i-1} + f(t_{i-1}, y_{i-1}) \\cdot h$ (that is, the new approximate $y$-value is the previous one, plus the step size times the derivative at the previous $t$ and $y$ values.)\n",
    "\n",
    "And continue this process until you have approximate values at all the $t$-values in which you are interested. \n",
    "\n",
    "## What Euler's method is actually doing \n",
    "\n",
    "Euler's method is essentially **approximating the function $y$ by replacing it with a Taylor series expansion for $y$ with two terms.** Recall from Calculus 2 that if $f$ is a function (all of whose derivatives exist), then the Taylor series expansion at a value $a$ is given by: \n",
    "\n",
    "$$f(t) = f(a) +  \\frac{f'(a)}{1!}(t-a) + \\frac{f''(a)}{2!}(x-a)^2 + \\frac{f'''(a)}{3!}(x-a)^3 + \\cdots$$\n",
    "\n",
    "And you can *approximate* $f$ with a polynomial, by only using a finite number of these terms. If we just used the first two terms, we'd have: \n",
    "\n",
    "$$f(t) \\approx f(a) + f'(a)(t-a)$$\n",
    "\n",
    "since $1! = 1$. And this is basically the formula used in Euler's Method, because if we started at $t_0$ and wanted to find the value of $y$ at $t_1$, we'd have: \n",
    "\n",
    "$$y(t_1) \\approx y(t_0) + y'(t_0)(t_1-t_0)$$\n",
    "\n",
    "And note that in the last part, $t_1 - t_0$ is the step size. \n",
    "\n",
    "## Runge-Kutta methods\n",
    "\n",
    "So it would be reasonable to ask, what if we use *three* terms of the Taylor series expansion instead of two? If you did that, you would have what's called a **second-order Runge-Kutta approximation** or \"RK2\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7c34d-6149-4b0d-b279-e87204179067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
